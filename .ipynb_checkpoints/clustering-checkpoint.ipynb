{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "from scipy.spatial.distance import cdist\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = codecs.open('full_parsed.json', 'r', encoding='utf-8')\n",
    "data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(86, 2092)\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "def tfidf_docterm(corpus, freqthresh):\n",
    "    \"\"\"Estimate document-term TF-IDF vectors for each document (line in filename),\n",
    "    where each column is a word, in decreasing order of frequency.\n",
    "    Ignore words that appear fewer than freqthresh times.\n",
    "    Return a list consisting of\n",
    "    1. a list of the m word types with at least freqthresh count, sorted in decreasing order of frequency.\n",
    "    2. an array with d rows and m columns,\n",
    "    where row i is the vector for the ith document in filename,\n",
    "    and col j represents the jth word in the above list.\n",
    "    \"\"\"\n",
    "    tfidf_dict = dict()\n",
    "    candidate_dict = {}\n",
    "    wordcounts = defaultdict(int)\n",
    "    new_corpus = []\n",
    "    labels = []\n",
    "    for candidate in corpus.keys(): \n",
    "        if candidate == 'Hillary Clinton republican 2008':\n",
    "            continue\n",
    "        labels.append(candidate)\n",
    "        debates = [debate for debates in corpus[candidate].values() for debate in debates]\n",
    "        for word in debates:\n",
    "                if word not in common:\n",
    "                    wordcounts[word] +=1\n",
    "        new_corpus.append([candidate, debates])\n",
    "    \n",
    "    sorted_words = sorted(filter(lambda x: wordcounts[x] >= freqthresh, wordcounts.keys()), key=lambda x: wordcounts[x], reverse=True)\n",
    "    thresholded_words = set(sorted_words)\n",
    "    word_indices = dict((word, index) for index, word in enumerate(sorted_words))\n",
    "    context = numpy.zeros((len(new_corpus), len(sorted_words)))\n",
    "    for di, doc in enumerate(new_corpus):\n",
    "        for word in doc[1]:\n",
    "            try:\n",
    "                #print word\n",
    "                if word in thresholded_words:\n",
    "                    context[di,word_indices[word]] +=1\n",
    "            except: \n",
    "                pass\n",
    "    return [sorted_words, context, labels]\n",
    "\n",
    "common = stopwords.words('english')\n",
    "\n",
    "tfidf_vectors = tfidf_docterm(data,50)\n",
    "vectorizer = tfidf_vectors[1]\n",
    "names = tfidf_vectors[2]\n",
    "print vectorizer.shape\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -2.37011477e+01  -6.28903182e+00   5.06144780e+01 ...,  -7.24799360e+00\n",
      "    3.71637075e+01  -3.11825114e+02]\n",
      " [  6.46835736e+00  -1.49982616e+00  -2.46058564e+00 ...,  -9.06679916e+00\n",
      "   -2.67053644e+00  -7.78438509e+01]\n",
      " [  4.45714852e+01   8.52065842e+00  -1.25616449e+01 ...,   6.85708854e+01\n",
      "   -1.28931130e+02  -6.57327364e+02]\n",
      " ..., \n",
      " [  1.68895793e+01   1.01576821e+01  -3.99283063e+01 ...,   6.43042066e+01\n",
      "   -1.40726571e+02  -9.96131281e+02]\n",
      " [ -2.60904260e-13  -2.54835363e-13   7.06407528e-14 ...,  -7.76237355e-14\n",
      "    1.90314815e-14  -1.24785116e-13]\n",
      " [  1.77244947e+01  -4.89688044e+01   2.29170569e+01 ...,  -1.85882736e+01\n",
      "    4.90046161e+01  -3.18415228e+02]] <class 'numpy.matrixlib.defmatrix.matrix'> (86, 20)\n"
     ]
    }
   ],
   "source": [
    "def dimensionality_reduce(vectors, ndims):\n",
    "    \"\"\"Apply SVD on original sparse matrix, return reduced vectors.\"\"\"\n",
    "    # Do not modify\n",
    "    U, s, Vh = scipy.sparse.linalg.svds(vectors, k=ndims)\n",
    "    sigmatrix = scipy.matrix(scipy.diag(s))\n",
    "    return U * sigmatrix\n",
    "\n",
    "data_features = dimensionality_reduce(vectorizer, 20)\n",
    "print data_features, type(data_features), data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def kmeans(points, labels, k, maxiter):\n",
    "    \"\"\"Cluster points (named with corresponding labels) into k groups.\n",
    "    Return a dictionary mapping each cluster ID (from 0 through k-1)\n",
    "    to a list of the labels of the points that belong to that cluster.\n",
    "    \"\"\"\n",
    "    clusters = points[0:k,:].copy() # initialize k centroids with the first k points from data\n",
    "    iteration = 0\n",
    "    converged = False\n",
    "    while converged == False and iteration <= maxiter:\n",
    "        #print clusters[:,0]\n",
    "        distances = cdist(points, clusters) # calculates dist between each pair\n",
    "        cluster_pts = [[] for _ in range(k)] # create k empty groups\n",
    "        for pi in range(len(points)): # loop through each point\n",
    "            ci = min(enumerate(distances[pi]), key = lambda e: e[1])[0]\n",
    "            cluster_pts[ci].append(pi)\n",
    "        converged_count = 0 # keeps track of how many have converged\n",
    "        for ci in range(k):\n",
    "            if cluster_pts[ci] == []:\n",
    "                new_centroid = points[ci]\n",
    "            else:\n",
    "                new_centroid = numpy.mean(points[cluster_pts[ci]], axis = 0) # find average of all set of points\n",
    "            if not (new_centroid == clusters[ci]).all(): # still has not converged\n",
    "                clusters[ci] = new_centroid\n",
    "            else:\n",
    "                converged_count += 1  \n",
    "        if converged_count == k:\n",
    "            converged = True  \n",
    "        iteration += 1\n",
    "    print iteration\n",
    "    return dict((ci, [labels[pi] for pi in cluster_pts[ci]]) for ci in range(k))\n",
    "\n",
    "# Marena\n",
    "def kmeans(points, labels, k, maxiter):\n",
    "    \"\"\"Cluster points (named with corresponding labels) into k groups.\n",
    "    Return a dictionary mapping each cluster ID (from 0 through k-1)\n",
    "    to a list of the labels of the points that belong to that cluster.\n",
    "    \"\"\"\n",
    "    centroids = points[0:k].copy()\n",
    "    count = 0\n",
    "    old_points = []\n",
    "    labeled_points = {}\n",
    "    while count < maxiter:\n",
    "        cd = cdist(points, centroids, 'euclidean') # Creates array where i,j is distance between points[i] and centroids[j]\n",
    "        min_indices = numpy.argmin(cd, axis=1) # List of which centroid (0 through k-1) each point is closest to\n",
    "        # Assign points and labels to cluster dictionary / list\n",
    "        new_points = [[] for c in range(0,k)]\n",
    "        labels_dict = dict((c,[]) for c in range(0,k))\n",
    "        for index, cluster in enumerate(min_indices):\n",
    "            new_points[cluster].append(points[index])\n",
    "            labels_dict[cluster].append(labels[index])\n",
    "        # Check that the clusters have changed, break if they haven't\n",
    "        if numpy.array_equal(old_points, new_points):\n",
    "            break\n",
    "        # Calculate new centroids\n",
    "        for cluster, cluster_points in enumerate(new_points):\n",
    "            if len(cluster_points) == 0:\n",
    "                centroids[cluster] = points[cluster]\n",
    "            else:\n",
    "                centroids[cluster] = numpy.mean(cluster_points, axis=0)\n",
    "        old_points = new_points\n",
    "        labeled_points = labels_dict\n",
    "        count += 1\n",
    "    return labels_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "{0: [u'John Edwards democratic 2008', u'Hillary Clinton democratic 2016', u'Bill Bradley democratic 2000', u'Mitt Romney republican 2012', u'Mitt Romney republican 2008', u'Hillary Clinton democratic 2008', u'Rick Santorum republican 2012', u'Newt Gingrich republican 2012', u'John Kasich republican 2016', u'Rudolph Giuliani republican 2008', u'Donald Trump republican 2016', u'Mike Huckabee republican 2008', u'Marco Rubio republican 2016', u'Barack Obama democratic 2008', u'Bernie Sanders democratic 2016', u'Ron Paul republican 2012'], 1: [u'Jimmy Carter presidential 1976', u'Wesley Clark democratic 2004', u'Ted Cruz republican 2016', u'Richard Nixon presidential 1960', u'John Edwards democratic 2004', u'Fred Thompson republican 2008', u'John McCain republican 2000', u'Steve Forbes republican 2000', u'Joe Biden democratic 2008', u'Jimmy Carter presidential 1980', u'Jon Huntsman republican 2012', u'Herman Cain republican 2012', u'Walter F. Mondale presidential 1984', u'Christopher Dodd democratic 2008', u'Mitt Romney presidential 2012', u'Gary Bauer republican 2000', u'Bill Clinton presidential 1992', u'James Gilmore republican 2008', u'Tom Tancredo republican 2008', u'Bill Clinton presidential 1996', u'Rand Paul republican 2016', u'Sam Brownback republican 2008', u'Rick Santorum republican 2016', u'John Anderson presidential 1980', u'Ross Perot presidential 1992', u'Al Sharpton democratic 2004', u'Ronald Reagan presidential 1984', u'Ronald Reagan presidential 1980', u'Howard Dean democratic 2004', u'John Kerry democratic 2004', u'Bob Dole presidential 1996', u'Orrin Hatch republican 2000', u'George W. Bush republican 2000', u'Duncan Hunter republican 2008', u'Ben Carson republican 2016', u'Mike Huckabee republican 2016', u'Mike Gravel democratic 2008', u'John McCain presidential 2008', u'Carly Fiorina republican 2016', u'George H. W. Bush presidential 1992', u'John McCain republican 2008', u'Jeb Bush republican 2016', u'Alan Keyes republican 2000', u'Al Gore presidential 2000', u'John Kerry presidential 2004', u'George H. W. Bush presidential 1988', u'Alan Keyes republican 2008', u'Barack Obama presidential 2008', u'Michele Bachmann republican 2012', u'Bill Richardson democratic 2008', u'Michael Dukakis presidential 1988', u'Buddy Roemer republican 2012', u'Rick Perry republican 2012', u'Joe Lieberman democratic 2004', u'Barack Obama presidential 2012', u'Vermin Supreme democratic 2016', u'George W. Bush presidential 2004', u'George W. Bush presidential 2000', u'Tommy Thompson republican 2008', u'Dennis Kucinich democratic 2008', u'Dennis Kucinich democratic 2004', u'Ron Paul republican 2008', u'Tim Pawlenty republican 2012', u'Chris Christie republican 2016', u'Al Gore democratic 2000', u\"Martin O'Malley democratic 2016\", u'Gerald Ford presidential 1976', u'Jim Gilmore republican 2016', u'Fred Karger republican 2012', u'John F. Kennedy presidential 1960']}\n"
     ]
    }
   ],
   "source": [
    "clusters = kmeans(data_features, names, 2, 30)\n",
    "print clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
