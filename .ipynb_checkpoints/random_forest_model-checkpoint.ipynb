{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "import scipy.sparse.linalg\n",
    "import numpy\n",
    "from collections import defaultdict\n",
    "import json\n",
    "import codecs\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = codecs.open('parsed.json', 'r', encoding='utf-8')\n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = codecs.open('win_loss_labels.json', 'r', encoding='utf-8')\n",
    "results = json.load(f)\n",
    "f.close()\n",
    "\n",
    "f = codecs.open('parsed_testing.json', 'r', encoding='utf-8')\n",
    "test_data = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(53, 1399)\n",
      "[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "def tfidf_docterm(corpus, freqthresh):\n",
    "    \"\"\"Estimate document-term TF-IDF vectors for each document (line in filename),\n",
    "    where each column is a word, in decreasing order of frequency.\n",
    "    Ignore words that appear fewer than freqthresh times.\n",
    "    Return a list consisting of\n",
    "    1. a list of the m word types with at least freqthresh count, sorted in decreasing order of frequency.\n",
    "    2. an array with d rows and m columns,\n",
    "    where row i is the vector for the ith document in filename,\n",
    "    and col j represents the jth word in the above list.\n",
    "    \"\"\"\n",
    "    tfidf_dict = dict()\n",
    "    candidate_dict = {}\n",
    "    wordcounts = defaultdict(int)\n",
    "    new_corpus = []\n",
    "    labels = []\n",
    "    for candidate in corpus.keys(): \n",
    "        if candidate == 'Hillary Clinton republican 2008':\n",
    "            continue\n",
    "        labels.append(results[candidate])\n",
    "        debates = [debate for debates in corpus[candidate].values() for debate in debates]\n",
    "        for word in debates:\n",
    "                if word not in common:\n",
    "                    wordcounts[word] +=1\n",
    "        new_corpus.append([candidate, debates])\n",
    "    \n",
    "    sorted_words = sorted(filter(lambda x: wordcounts[x] >= freqthresh, wordcounts.keys()), key=lambda x: wordcounts[x], reverse=True)\n",
    "    thresholded_words = set(sorted_words)\n",
    "    word_indices = dict((word, index) for index, word in enumerate(sorted_words))\n",
    "    context = numpy.zeros((len(new_corpus), len(sorted_words)))\n",
    "    for di, doc in enumerate(new_corpus):\n",
    "        for word in doc[1]:\n",
    "            try:\n",
    "                #print word\n",
    "                if word in thresholded_words:\n",
    "                    context[di,word_indices[word]] +=1\n",
    "            except: \n",
    "                pass\n",
    "    return [sorted_words, context, labels]\n",
    "\n",
    "common = stopwords.words('english')\n",
    "\n",
    "tfidf_vectors = tfidf_docterm(data,50)\n",
    "vectorizer = tfidf_vectors[1]\n",
    "result = tfidf_vectors[2]\n",
    "print vectorizer.shape\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  -3.82670867    1.56969255   -0.95818609 ...,    9.11066367\n",
      "    -2.13700424  -77.6101968 ]\n",
      " [  -8.25540067   11.83665582   -3.33705647 ...,   25.68261294\n",
      "   -15.38189016 -479.80194031]\n",
      " [ -50.69721222  -80.07391666  -27.89746094 ...,   70.80272083\n",
      "   -35.77168279 -512.9112537 ]\n",
      " ..., \n",
      " [ -10.12864488  -20.8345388     4.57299857 ...,  -13.95186028\n",
      "   -11.83080993 -191.22507628]\n",
      " [ -71.3857324    -7.78533655   16.79635823 ...,  -64.28246144\n",
      "    -3.29635289 -319.76082287]\n",
      " [ -44.15076785    5.71621032    7.47670045 ...,  -17.38807814   24.4171316\n",
      "  -298.50243687]] <class 'numpy.matrixlib.defmatrix.matrix'> (53, 20)\n"
     ]
    }
   ],
   "source": [
    "def dimensionality_reduce(vectors, ndims):\n",
    "    \"\"\"Apply SVD on original sparse matrix, return reduced vectors.\"\"\"\n",
    "    # Do not modify\n",
    "    U, s, Vh = scipy.sparse.linalg.svds(vectors, k=ndims)\n",
    "    sigmatrix = scipy.matrix(scipy.diag(s))\n",
    "    return U * sigmatrix\n",
    "\n",
    "train_data_features = dimensionality_reduce(vectorizer, 20)\n",
    "print train_data_features, type(train_data_features), train_data_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the random forest...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print \"Training the random forest...\"\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, result)\n",
    "\n",
    "print \"Done\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 111.   87.  141. ...,    6.    0.    6.]\n",
      " [ 214.  117.   92. ...,    1.    1.    2.]\n",
      " [ 336.  147.  113. ...,    4.    3.    1.]\n",
      " ..., \n",
      " [ 526.  226.  269. ...,   23.    0.    4.]\n",
      " [ 575.  564.  360. ...,    6.   10.    6.]\n",
      " [   0.    0.    0. ...,    0.    0.    0.]]\n",
      "[1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "test_tfidf_vectors = tfidf_docterm(test_data,100)\n",
    "test_vectorizer = test_tfidf_vectors[1]\n",
    "test_result = test_tfidf_vectors[2]\n",
    "print test_vectorizer\n",
    "print test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "0.757575757576\n",
      "[u'Jimmy Carter presidential 1976', u'Rick Santorum republican 2016', u'Ted Cruz republican 2016', u'George W. Bush presidential 2000', u'Carly Fiorina republican 2016', u'George H. W. Bush presidential 1992', u'Jeb Bush republican 2016', u'Alan Keyes republican 2000', u'Al Gore presidential 2000', u'Hillary Clinton democratic 2016', u'John McCain republican 2000', u'Bill Bradley democratic 2000', u'Ross Perot presidential 1992', u'Steve Forbes republican 2000', u'Chris Christie republican 2016', u'Ronald Reagan presidential 1984', u'Al Gore democratic 2000', u\"Martin O'Malley democratic 2016\", u'Gerald Ford presidential 1976', u'John Kasich republican 2016', u'Bernie Sanders democratic 2016', u'Walter F. Mondale presidential 1984', u'Jim Gilmore republican 2016', u'Gary Bauer republican 2000', u'George W. Bush republican 2000', u'Bill Clinton presidential 1992', u'Ben Carson republican 2016', u'Mike Huckabee republican 2016', u'Rand Paul republican 2016', u'Orrin Hatch republican 2000', u'Marco Rubio republican 2016', u'Donald Trump republican 2016', u'Vermin Supreme democratic 2016']\n"
     ]
    }
   ],
   "source": [
    "test_data_features = dimensionality_reduce(test_vectorizer, 20)\n",
    "test_predict_label = forest.predict(test_data_features)\n",
    "\n",
    "print test_predict_label\n",
    "count = 0 \n",
    "for index,label in enumerate(test_predict_label):\n",
    "    if label == test_result[index]:\n",
    "        count+=1\n",
    "print count/33. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
